{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP-Assignment.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOjPmd615yx/id2nkT2OsRW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/miguelangel43/IS_NLP_Assignment/blob/main/NLP_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "dCRjzCSEQ94S",
        "outputId": "fe8cf7e3-41f1-445c-d697-f47010d3e1d0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-372ba218-0cc3-47b0-9009-8ca056a15e01\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-372ba218-0cc3-47b0-9009-8ca056a15e01\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving yelp_20200.csv to yelp_20200.csv\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcdDGYWQRipo",
        "outputId": "64065724-9b65-4ed8-a3a5-42ba4ecbd037"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read dataset \n",
        "df = pd.read_csv(\"yelp_20200.csv\")\n",
        "\n",
        "# Separate the text and the labels\n",
        "labels = df['stars'].tolist() \n",
        "text_unprocessed = df['text'].tolist() "
      ],
      "metadata": {
        "id": "XPlaOV3vRwwF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------------------------\n",
        "# Preprocessing the text\n",
        "# --------------------------------------------------------------------\n",
        "\n",
        "# 1. Tokenization\n",
        "tokenizer = RegexpTokenizer(r'\\w+') # The pattern (r'\\w') also removes punctuation\n",
        "#df['Review'] = df['Review'].progress_apply(lambda x: tokenizer.tokenize(x.lower())) # Apply(): applies a function along an axis of the DataFrame.\n",
        "texts_tok = []\n",
        "for x in tqdm(text_unprocessed):\n",
        "    texts_tok.append(tokenizer.tokenize(x.lower()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8O3jCHr3R1gJ",
        "outputId": "da855bda-0d6d-4c9b-81de-77e8ffde580d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20200/20200 [00:00<00:00, 22114.64it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Remove stop words\n",
        "stwords = set(stopwords.words('english')[: -63]) # Don't remove useful words for sentiment analysis\n",
        "def remove_stopwords(text):\n",
        "    return [w for w in text if w not in stwords]\n",
        "#df['Review'] = df['Review'].progress_apply(lambda x : remove_stopwords(x))\n",
        "texts_st = []\n",
        "for x in tqdm(texts_tok):\n",
        "    texts_st.append(remove_stopwords(x))\n",
        "# Reduce the number of words that we take from each review bc of memory issues \n",
        "texts_st = [text[:20] for text in texts_st]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qe55G1uVR9xz",
        "outputId": "b06a60b9-1d16-4328-ba89-905e214cc046"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20200/20200 [00:00<00:00, 50365.32it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Lemmatization\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "def word_lemmatizer(text):\n",
        "    return [lemmatizer.lemmatize(i) for i in text]\n",
        "#tqdm.pandas(tqdm_notebook)\n",
        "#df['Review'] = df['Review'].progress_apply(lambda x : word_lemmatizer(x))\n",
        "texts_lem = []\n",
        "for x in tqdm(texts_st):\n",
        "    texts_lem.append(word_lemmatizer(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-RQh6_LSAId",
        "outputId": "9a2f3edf-ef2a-4c2d-db09-08d65225dc14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20200/20200 [00:01<00:00, 12459.90it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Stemming\n",
        "stemmer = PorterStemmer()\n",
        "def word_stemmer(text):\n",
        "    return [stemmer.stem(i) for i in text]\n",
        "# tqdm.pandas(tqdm_notebook)\n",
        "# df['Review'] = df['Review'].progress_apply(lambda x: word_stemmer(x))\n",
        "texts = []\n",
        "for x in tqdm(texts_lem):\n",
        "    texts.append(word_stemmer(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qa_hGpcSByj",
        "outputId": "7482c67b-af4f-4eb0-c9e4-4e711c584a30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 20200/20200 [00:08<00:00, 2486.35it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(labels_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89-pmYPIvAkQ",
        "outputId": "f3130ceb-30d2-4152-bab9-7ce547016464"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------------------------\n",
        "# Preparing the input for training\n",
        "# --------------------------------------------------------------------\n",
        "\n",
        "SIZE_TRAIN_DATASET = 20000\n",
        "SIZE_TEST_DATASET = 200\n",
        "\n",
        "texts_train = texts[:SIZE_TRAIN_DATASET]\n",
        "labels_train = labels[:SIZE_TRAIN_DATASET]\n",
        "texts_test = texts[SIZE_TRAIN_DATASET:SIZE_TRAIN_DATASET+SIZE_TEST_DATASET]\n",
        "labels_test = labels[SIZE_TRAIN_DATASET:SIZE_TRAIN_DATASET+SIZE_TEST_DATASET]\n",
        "\n",
        "def word2indexMapping(textfile):\n",
        "    w2i = {}\n",
        "    text_wo_dup = list(dict.fromkeys(textfile))\n",
        "    i = 0\n",
        "    for word in text_wo_dup:\n",
        "        w2i[word] = i\n",
        "        i += 1\n",
        "    return w2i\n",
        "\n",
        "texts_words = [val for sublist in texts_train for val in sublist] # We put each word in a list to then make a w2i out of it\n",
        "w2i = word2indexMapping(texts_words) #textfile is all the reviews put together\n",
        "\n",
        "def onehot(length, position): # We create this method because np.eye or np.identity consumes too much memory\n",
        "    l = []\n",
        "    for i in range(length):\n",
        "        if position == i:\n",
        "            l.append(1)\n",
        "        else:\n",
        "            l.append(0)\n",
        "    return np.array(l)\n",
        "\n",
        "#https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "class YelpDataset(Dataset):\n",
        "\n",
        "    def __init__(self, texts, labels, w2i, max_length=20): \n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.w2i = w2i\n",
        "        self.length_dict = len(self.w2i)\n",
        "        self.max_length = max_length\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        data = np.array([onehot(self.length_dict, self.w2i[word]) for word in self.texts[idx] if word in self.w2i]).astype(np.float32)\n",
        "        if len(data) > self.max_length:\n",
        "            data = data[:self.max_length].astype(np.float32)\n",
        "        elif 0 < len(data) < self.max_length:\n",
        "            data = np.concatenate((data, np.zeros((self.max_length - len(data), self.length_dict), dtype=np.float32)))\n",
        "        elif len(data) == 0:\n",
        "            data = np.zeros((self.max_length, self.length_dict), dtype=np.float32)\n",
        "        label = self.labels[idx]\n",
        "        return data, label\n",
        "\n",
        "yelp_dataset_train = YelpDataset(texts=texts_train, labels=labels_train, w2i=w2i)\n",
        "yelp_dataset_test = YelpDataset(texts=texts_test, labels=labels_test, w2i=w2i)"
      ],
      "metadata": {
        "id": "Fkl50cgvSIIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------------------------\n",
        "# Convolutional Neural Network\n",
        "# --------------------------------------------------------------------\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ConvolutionalNeuralNetwork(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes=5, input_dim=yelp_dataset_train.length_dict, input_length=20):\n",
        "        super(ConvolutionalNeuralNetwork, self).__init__()\n",
        "        # input channel (no. columns of sentence matrix),  256 output channels, 1x7 convolution\n",
        "        self.conv1 = nn.Conv1d(input_length, 256, kernel_size=7)\n",
        "        self.conv2 = nn.Conv1d(256, 256, kernel_size=7)\n",
        "        \n",
        "        self.fc1 = nn.Linear(456192, num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.max_pool1d(F.relu(self.conv1(x)), 3)\n",
        "        # If the size is a square you can only specify a single number\n",
        "        x = F.max_pool1d(F.relu(self.conv2(x)), 3)\n",
        "        x = x.view(-1, self.num_flat_features(x))\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "    \n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n",
        "# %%\n",
        "cnn = ConvolutionalNeuralNetwork()\n",
        "device = torch.device(\"cuda:0\")\n",
        "cnn.to(device)\n",
        "# %%\n",
        "from torch.optim import Adam\n",
        "from IPython.display import clear_output\n",
        "#from tqdm import tqdm\n",
        "\n",
        "def trainCNN(model, train_dataset, epochs=3, batchsize=32, learning_rate=0.0001):\n",
        "    # write your code snippet here\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=batchsize)\n",
        "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
        "    \n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "    for i in range(epochs):\n",
        "        print('epoch: ', i+1)\n",
        "        counter = 0\n",
        "        for inp,labels in train_dataloader:\n",
        "            clear_output()\n",
        "            print(counter)\n",
        "            counter += 1\n",
        "            inp, labels = inp.to(device), labels.to(device)\n",
        "            \n",
        "            out = model(inp.float())\n",
        "            loss = criterion(out, labels-1)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        \n",
        "    print('training succesful!')\n",
        "\n",
        "trainCNN(cnn, yelp_dataset_train)"
      ],
      "metadata": {
        "id": "DiNlFGI6SdUy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "688e8ed1-0e6b-4d5c-91ff-715e0ac05a88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "624\n",
            "training succesful!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#torch.save(cnn.state_dict(), 'cnn_t1.pt')"
      ],
      "metadata": {
        "id": "7N-lqLtfTnjC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#files.download('cnn_t1.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "F0E5CszetHB4",
        "outputId": "7eb9335c-1b3c-4e3f-b9f9-972fa243d145"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_20bc5bcb-12e2-4d06-9964-f1b0aac2d560\", \"cnn_t1.pt\", 11111319)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------------------------\n",
        "# Testing\n",
        "# --------------------------------------------------------------------\n",
        "\n",
        "def test(model, test_dataset, batchsize=1):\n",
        "    print('Testing...')\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=batchsize)\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for data, label in test_dataloader:\n",
        "        data, label = data.to(device), label.to(device)\n",
        "        out = model(data.float())\n",
        "        if torch.argmax(out) == label-1:\n",
        "            correct += 1\n",
        "        total += 1\n",
        "    print('Correct: ', correct)\n",
        "    print('Total: ', total)\n",
        "    print('Accuracy: ', correct/total)"
      ],
      "metadata": {
        "id": "_Sgdt8uVUNv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ConvolutionalNeuralNetwork()\n",
        "model.load_state_dict(torch.load(\"cnn_t1.pt\"))\n",
        "model.eval()\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "9AFFvlqzUYIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing CNN\n",
        "test(cnn, yelp_dataset_test)"
      ],
      "metadata": {
        "id": "93OAA1o_Ua7y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51c5dab2-cffe-4232-a278-48bd40e7fc1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing...\n",
            "Correct:  76\n",
            "Total:  200\n",
            "Accuracy:  0.38\n"
          ]
        }
      ]
    }
  ]
}